{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d432360b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Documents\\UNAI_Notes\\CVD-PINN-Project\\cvdenv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\Documents\\UNAI_Notes\\CVD-PINN-Project\\cvdenv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\Documents\\UNAI_Notes\\CVD-PINN-Project\\cvdenv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import os\n",
    "import time\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7babc2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.19.0\n",
      "TensorFlow Probability version: 0.25.0\n",
      "No GPUs available, using CPU\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"TensorFlow Probability version:\", tfp.__version__)\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "os.makedirs(\"figures\", exist_ok=True)\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "os.makedirs(\"streamlit_app\", exist_ok=True)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"GPUs available: {len(gpus)}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPUs available, using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c57a69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#---------------------------------------------------------------------------\n",
    "# Section 1: Base PINN Network and Loss Functions\n",
    "#---------------------------------------------------------------------------\n",
    "class PINN(tf.keras.Model):\n",
    "    \"\"\"Base Physics-Informed Neural Network class\"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_layers, activation='tanh', name=\"pinn\"):\n",
    "        \"\"\"\n",
    "        Initialize PINN model\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        hidden_layers : list\n",
    "            List of integers, each specifying the number of neurons in each hidden layer\n",
    "        activation : str\n",
    "            Activation function to use in hidden layers\n",
    "        name : str\n",
    "            Name of the model\n",
    "        \"\"\"\n",
    "        super(PINN, self).__init__(name=name)\n",
    "        \n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.layers_list = []\n",
    "        \n",
    "        for units in hidden_layers:\n",
    "            self.layers_list.append(\n",
    "                tf.keras.layers.Dense(\n",
    "                    units, \n",
    "                    activation=activation,\n",
    "                    kernel_initializer=tf.keras.initializers.GlorotNormal()\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # For CVD model: outputs are concentration and temp\n",
    "        self.layers_list.append(\n",
    "            tf.keras.layers.Dense(\n",
    "                5,  \n",
    "                activation=None,\n",
    "                kernel_initializer=tf.keras.initializers.GlorotNormal()\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \"\"\"Forward pass through the network\"\"\"\n",
    "        x = inputs\n",
    "        for layer in self.layers_list:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    @tf.function\n",
    "    def get_gradients(self, x, y):\n",
    "        \"\"\"\n",
    "        Compute gradients of output with respect to input\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        x : tf.Tensor\n",
    "            Input tensor, shape (batch_size, 3)\n",
    "            Representing (x, y, t) coordinates\n",
    "        y : tf.Tensor\n",
    "            Output tensor, shape (batch_size, 5)\n",
    "            Representing [SiH4, Si, H2, SiH2, T]\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        dict\n",
    "            Dictionary containing first and second derivatives\n",
    "        \"\"\"\n",
    "        with tf.GradientTape(persistent=True) as tape2:\n",
    "            tape2.watch(x)\n",
    "            with tf.GradientTape(persistent=True) as tape1:\n",
    "                tape1.watch(x)\n",
    "                y_pred = self(x)\n",
    "                \n",
    "            dy_dx = tape1.batch_jacobian(y_pred, x)\n",
    "            \n",
    "            y_x = dy_dx[..., 0]  # derivatives w.r.t. x\n",
    "            y_y = dy_dx[..., 1]  # derivatives w.r.t. y\n",
    "            y_t = dy_dx[..., 2]  # derivatives w.r.t. t\n",
    "            \n",
    "        # Second derivatives\n",
    "        dy_xx = tape2.batch_jacobian(y_x, x)[..., 0]  # d²y/dx²\n",
    "        dy_yy = tape2.batch_jacobian(y_y, x)[..., 1]  # d²y/dy²\n",
    "        \n",
    "        del tape1, tape2\n",
    "        \n",
    "        # Return all derivatives\n",
    "        return {\n",
    "            'dy_dx': dy_dx,\n",
    "            'y_x': y_x,\n",
    "            'y_y': y_y,\n",
    "            'y_t': y_t,\n",
    "            'y_xx': dy_xx,\n",
    "            'y_yy': dy_yy\n",
    "        }\n",
    "\n",
    "#---------------------------------------------------------------------------\n",
    "# Section 2: Physical Parameters and Constants for CVD Model\n",
    "#---------------------------------------------------------------------------\n",
    "\n",
    "class CVDPhysicalParams:\n",
    "    \"\"\"Class to store and manage physical parameters for CVD simulation\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Initialize with default parameters for silicon CVD from silane\n",
    "        \n",
    "        # Diffusion coefficients (m²/s)\n",
    "        self.D_SiH4 = 1.0e-5 \n",
    "        self.D_Si = 5.0e-6    \n",
    "        self.D_H2 = 4.0e-5    \n",
    "        self.D_SiH2 = 1.5e-5  \n",
    "        \n",
    "        # Thermal properties\n",
    "        self.thermal_conductivity = 0.1  # W/(m·K)\n",
    "        self.specific_heat = 700.0      # J/(kg·K)\n",
    "        self.density = 1.0              # kg/m³\n",
    "        \n",
    "        self.A1 = 1.0e6     # Pre-exponential factor\n",
    "        self.E1 = 1.5e5     # Activation energy (J/mol)\n",
    "        \n",
    "        self.A2 = 2.0e5     # Pre-exponential factor\n",
    "        self.E2 = 1.2e5     # Activation energy (J/mol)\n",
    "\n",
    "        self.A3 = 3.0e5     # Pre-exponential factor\n",
    "        self.E3 = 1.0e5     # Activation energy (J/mol)\n",
    "        \n",
    "        self.R = 8.314\n",
    "    \n",
    "    def get_reaction_rates(self, concentrations, temperature):\n",
    "        \"\"\"\n",
    "        Calculate reaction rates based on Arrhenius equation\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        concentrations : tf.Tensor\n",
    "            Concentrations of species [SiH4, Si, H2, SiH2]\n",
    "        temperature : tf.Tensor\n",
    "            Temperature\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        tuple\n",
    "            (R1, R2, R3) - Reaction rates for the three reactions\n",
    "        \"\"\"\n",
    "        SiH4, Si, H2, SiH2 = concentrations\n",
    "        T = temperature\n",
    "        \n",
    "        # Reaction 1: SiH4 -> Si + 2H2\n",
    "        R1 = self.A1 * tf.exp(-self.E1 / (self.R * T)) * SiH4\n",
    "        \n",
    "        # Reaction 2: SiH4 + H2 -> SiH2 + 2H2\n",
    "        R2 = self.A2 * tf.exp(-self.E2 / (self.R * T)) * SiH4 * H2\n",
    "        \n",
    "        # Reaction 3: SiH2 + SiH4 -> Si2H6\n",
    "        R3 = self.A3 * tf.exp(-self.E3 / (self.R * T)) * SiH2 * SiH4\n",
    "        \n",
    "        return R1, R2, R3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc7cb009",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------\n",
    "# Section 3: PDE Residuals for CVD Model\n",
    "#---------------------------------------------------------------------------\n",
    "\n",
    "class CVDPDE:\n",
    "    \"\"\"Class to compute PDE residuals for CVD simulation\"\"\"\n",
    "    \n",
    "    def __init__(self, phys_params):\n",
    "        \"\"\"\n",
    "        Initialize with physical parameters\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        phys_params : CVDPhysicalParams\n",
    "            Object containing physical parameters\n",
    "        \"\"\"\n",
    "        self.params = phys_params\n",
    "    \n",
    "    def compute_residuals(self, x_coords, y_pred, derivatives):\n",
    "        \"\"\"\n",
    "        Compute residuals for all PDEs in the CVD model\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        x_coords : tf.Tensor\n",
    "            Input coordinates (x, y, t)\n",
    "        y_pred : tf.Tensor\n",
    "            Predicted values [SiH4, Si, H2, SiH2, T]\n",
    "        derivatives : dict\n",
    "            Dictionary of derivatives computed by PINN.get_gradients()\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        tuple\n",
    "            (res_SiH4, res_Si, res_H2, res_SiH2, res_T) - Residuals for each equation\n",
    "        \"\"\"\n",
    "        SiH4 = y_pred[:, 0:1]\n",
    "        Si = y_pred[:, 1:2]\n",
    "        H2 = y_pred[:, 2:3]\n",
    "        SiH2 = y_pred[:, 3:4]\n",
    "        T = y_pred[:, 4:5]\n",
    "        \n",
    "        y_t = derivatives['y_t']\n",
    "        y_xx = derivatives['y_xx']\n",
    "        y_yy = derivatives['y_yy']\n",
    "        \n",
    "        SiH4_t = y_t[:, 0:1]\n",
    "        Si_t = y_t[:, 1:2]\n",
    "        H2_t = y_t[:, 2:3]\n",
    "        SiH2_t = y_t[:, 3:4]\n",
    "        T_t = y_t[:, 4:5]\n",
    "        \n",
    "        # Second spatial derivatives (Laplacian terms)\n",
    "        SiH4_xx = y_xx[:, 0:1]\n",
    "        SiH4_yy = y_yy[:, 0:1]\n",
    "        \n",
    "        Si_xx = y_xx[:, 1:2]\n",
    "        Si_yy = y_yy[:, 1:2]\n",
    "        \n",
    "        H2_xx = y_xx[:, 2:3]\n",
    "        H2_yy = y_yy[:, 2:3]\n",
    "        \n",
    "        SiH2_xx = y_xx[:, 3:4]\n",
    "        SiH2_yy = y_yy[:, 3:4]\n",
    "        \n",
    "        T_xx = y_xx[:, 4:5]\n",
    "        T_yy = y_yy[:, 4:5]\n",
    "        \n",
    "        # Calculate reaction rates\n",
    "        R1, R2, R3 = self.params.get_reaction_rates(\n",
    "            [SiH4, Si, H2, SiH2],\n",
    "            T\n",
    "        )\n",
    "        \n",
    "        # Residuals for mass transport equations\n",
    "        # ∂C_i/∂t = D_i ∇²C_i + sum_j(v_ij * R_j)\n",
    "        \n",
    "        # Residual for SiH4\n",
    "        res_SiH4 = SiH4_t - self.params.D_SiH4 * (SiH4_xx + SiH4_yy) + R1 + R2 + R3\n",
    "        \n",
    "        # Residual for Si\n",
    "        res_Si = Si_t - self.params.D_Si * (Si_xx + Si_yy) - R1\n",
    "        \n",
    "        # Residual for H2\n",
    "        res_H2 = H2_t - self.params.D_H2 * (H2_xx + H2_yy) - 2 * R1 - 2 * R2\n",
    "        \n",
    "        # Residual for SiH2\n",
    "        res_SiH2 = SiH2_t - self.params.D_SiH2 * (SiH2_xx + SiH2_yy) - R2 + R3\n",
    "        \n",
    "        # Energy equation (heat transfer)\n",
    "        # ∂T/∂t = κ ∇²T + sum_j(ΔH_j * R_j) / (ρ * Cp)\n",
    "        \n",
    "        # Heat source term (simplified)\n",
    "        Q = 1000 * (R1 + 500 * R2 + 300 * R3)\n",
    "        \n",
    "        # Thermal diffusivity\n",
    "        thermal_diffusivity = self.params.thermal_conductivity / (self.params.density * self.params.specific_heat)\n",
    "        \n",
    "        # Residual for temperature\n",
    "        res_T = T_t - thermal_diffusivity * (T_xx + T_yy) - Q / (self.params.density * self.params.specific_heat)\n",
    "        \n",
    "        return res_SiH4, res_Si, res_H2, res_SiH2, res_T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4c8cde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------\n",
    "# Section 4: Data Generation for PINN Training\n",
    "#---------------------------------------------------------------------------\n",
    "\n",
    "class CVDDataGenerator:\n",
    "    \"\"\"Class to generate training data for CVD PINN\"\"\"\n",
    "    \n",
    "    def __init__(self, domain_bounds):\n",
    "        \"\"\"\n",
    "        Initialize with domain bounds\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        domain_bounds : dict\n",
    "            Dictionary with domain bounds (x_min, x_max, y_min, y_max, t_min, t_max)\n",
    "        \"\"\"\n",
    "        self.bounds = domain_bounds\n",
    "    \n",
    "    def generate_collocation_points(self, n_points):\n",
    "        \"\"\"\n",
    "        Generate random collocation points for PDE residuals\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        n_points : int\n",
    "            Number of points to generate\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        np.ndarray\n",
    "            Array of points, shape (n_points, 3)\n",
    "        \"\"\"\n",
    "        # Generate random points within domain bounds\n",
    "        x = np.random.uniform(self.bounds['x_min'], self.bounds['x_max'], n_points)\n",
    "        y = np.random.uniform(self.bounds['y_min'], self.bounds['y_max'], n_points)\n",
    "        t = np.random.uniform(self.bounds['t_min'], self.bounds['t_max'], n_points)\n",
    "        \n",
    "        # Stack coordinates\n",
    "        collocation_points = np.stack([x, y, t], axis=1)\n",
    "        \n",
    "        return collocation_points\n",
    "    \n",
    "    def generate_boundary_points(self, n_points_per_boundary):\n",
    "        \"\"\"\n",
    "        Generate boundary points for boundary conditions\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        n_points_per_boundary : int\n",
    "            Number of points to generate per boundary\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        dict\n",
    "            Dictionary with boundary points for each boundary\n",
    "        \"\"\"\n",
    "        # Time points - used for all boundaries\n",
    "        t = np.random.uniform(self.bounds['t_min'], self.bounds['t_max'], n_points_per_boundary)\n",
    "        \n",
    "        # Boundary points\n",
    "        # Lower boundary (y = y_min) - Inlet\n",
    "        x_lower = np.random.uniform(self.bounds['x_min'], self.bounds['x_max'], n_points_per_boundary)\n",
    "        y_lower = np.ones_like(x_lower) * self.bounds['y_min']\n",
    "        \n",
    "        # Upper boundary (y = y_max) - Substrate\n",
    "        x_upper = np.random.uniform(self.bounds['x_min'], self.bounds['x_max'], n_points_per_boundary)\n",
    "        y_upper = np.ones_like(x_upper) * self.bounds['y_max']\n",
    "        \n",
    "        # Left boundary (x = x_min) - Wall\n",
    "        y_left = np.random.uniform(self.bounds['y_min'], self.bounds['y_max'], n_points_per_boundary)\n",
    "        x_left = np.ones_like(y_left) * self.bounds['x_min']\n",
    "        \n",
    "        # Right boundary (x = x_max) - Wall\n",
    "        y_right = np.random.uniform(self.bounds['y_min'], self.bounds['y_max'], n_points_per_boundary)\n",
    "        x_right = np.ones_like(y_right) * self.bounds['x_max']\n",
    "        \n",
    "        # Stack coordinates\n",
    "        boundary_points = {\n",
    "            'inlet': np.stack([x_lower, y_lower, t], axis=1),\n",
    "            'substrate': np.stack([x_upper, y_upper, t], axis=1),\n",
    "            'left_wall': np.stack([x_left, y_left, t], axis=1),\n",
    "            'right_wall': np.stack([x_right, y_right, t], axis=1)\n",
    "        }\n",
    "        \n",
    "        return boundary_points\n",
    "    \n",
    "    def generate_initial_points(self, n_points):\n",
    "        \"\"\"\n",
    "        Generate initial condition points at t = t_min\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        n_points : int\n",
    "            Number of points to generate\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        np.ndarray\n",
    "            Array of points, shape (n_points, 3)\n",
    "        \"\"\"\n",
    "        # Generate random spatial points\n",
    "        x = np.random.uniform(self.bounds['x_min'], self.bounds['x_max'], n_points)\n",
    "        y = np.random.uniform(self.bounds['y_min'], self.bounds['y_max'], n_points)\n",
    "        t = np.ones_like(x) * self.bounds['t_min']\n",
    "        \n",
    "        # Stack coordinates\n",
    "        initial_points = np.stack([x, y, t], axis=1)\n",
    "        \n",
    "        return initial_points\n",
    "\n",
    "    def generate_uniform_grid(self, nx, ny, nt):\n",
    "        \"\"\"\n",
    "        Generate uniform grid for visualization\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        nx : int\n",
    "            Number of points in x direction\n",
    "        ny : int\n",
    "            Number of points in y direction\n",
    "        nt : int\n",
    "            Number of points in t direction\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        np.ndarray\n",
    "            Array of grid points, shape (nx*ny*nt, 3)\n",
    "        \"\"\"\n",
    "        # Generate grid points\n",
    "        x = np.linspace(self.bounds['x_min'], self.bounds['x_max'], nx)\n",
    "        y = np.linspace(self.bounds['y_min'], self.bounds['y_max'], ny)\n",
    "        t = np.linspace(self.bounds['t_min'], self.bounds['t_max'], nt)\n",
    "        \n",
    "        # Create meshgrid\n",
    "        X, Y, T = np.meshgrid(x, y, t, indexing='ij')\n",
    "        \n",
    "        # Stack coordinates\n",
    "        grid_points = np.stack([X.flatten(), Y.flatten(), T.flatten()], axis=1)\n",
    "        \n",
    "        return grid_points, (nx, ny, nt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63a80af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------\n",
    "# Section 5: Entropy-Langevin Dynamics for PINN Training\n",
    "#---------------------------------------------------------------------------\n",
    "\n",
    "class EntropyRegularizedLoss:\n",
    "    \"\"\"Class to compute entropy-regularized loss for ensemble of PINNs\"\"\"\n",
    "    \n",
    "    def __init__(self, alpha=0.1, beta=10.0):\n",
    "        \"\"\"\n",
    "        Initialize with entropy and temperature parameters\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        alpha : float\n",
    "            Entropy weight parameter\n",
    "        beta : float\n",
    "            Inverse temperature parameter\n",
    "        \"\"\"\n",
    "        self.alpha = tf.Variable(alpha, trainable=False, dtype=tf.float32)\n",
    "        self.beta = tf.Variable(beta, trainable=False, dtype=tf.float32)\n",
    "    \n",
    "    def compute_loss(self, losses, current_loss, current_gradient):\n",
    "        \"\"\"\n",
    "        Compute entropy-regularized loss and modified gradient\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        losses : list\n",
    "            List of loss values for each network in the ensemble\n",
    "        current_loss : tf.Tensor\n",
    "            Loss value for the current network\n",
    "        current_gradient : tf.Tensor\n",
    "            Gradient of the loss for the current network\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        tuple\n",
    "            (modified_loss, modified_gradient)\n",
    "        \"\"\"\n",
    "        # Convert losses to tensor\n",
    "        losses_tensor = tf.convert_to_tensor(losses, dtype=tf.float32)\n",
    "        \n",
    "        # Compute mean loss and mean gradient across ensemble\n",
    "        mean_loss = tf.reduce_mean(losses_tensor)\n",
    "        \n",
    "        # Compute entropy term\n",
    "        # S[p(θ)] ≈ log(mean(exp(-β*L(θ))))/β + constant\n",
    "        entropy_term = tf.math.log(tf.reduce_mean(tf.exp(-self.beta * losses_tensor))) / self.beta\n",
    "        \n",
    "        # Compute entropy-regularized loss\n",
    "        # L_tilde(θ) = L(θ) - α * S[p(θ)]\n",
    "        modified_loss = current_loss - self.alpha * entropy_term\n",
    "        \n",
    "        # Compute modified gradient\n",
    "        # ∇_θ L_tilde(θ) = ∇_θ L(θ) - α*β*(∇_θ L(θ) - mean(∇_θ L(θ)))\n",
    "        gradient_difference = current_gradient - mean_loss\n",
    "        modified_gradient = current_gradient - self.alpha * self.beta * gradient_difference\n",
    "        \n",
    "        return modified_loss, modified_gradient\n",
    "    \n",
    "    def update_parameters(self, iteration, max_iterations):\n",
    "        \"\"\"\n",
    "        Update alpha and beta parameters based on scheduling\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        iteration : int\n",
    "            Current iteration\n",
    "        max_iterations : int\n",
    "            Maximum number of iterations\n",
    "        \"\"\"\n",
    "        # Implement scheduling as described in the paper\n",
    "        # This is a simple linear scheduling for demonstration\n",
    "        progress = tf.cast(iteration / max_iterations, tf.float32)\n",
    "        \n",
    "        # Decrease alpha over time (less entropy regularization)\n",
    "        alpha_new = 0.1 * (1.0 - 0.9 * progress)\n",
    "        \n",
    "        # Increase beta over time (lower temperature, less noise)\n",
    "        beta_new = 10.0 * (1.0 + 9.0 * progress)\n",
    "        \n",
    "        # Update parameters\n",
    "        self.alpha.assign(alpha_new)\n",
    "        self.beta.assign(beta_new)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2bb1c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Physical parameters initialized:\n",
      "Diffusion coefficients: D_SiH4 = 1e-05, D_Si = 5e-06, D_H2 = 4e-05, D_SiH2 = 1.5e-05\n",
      "Thermal parameters: k = 0.1, Cp = 700.0, ρ = 1.0\n",
      "Reaction parameters: A1 = 1000000.0, E1 = 150000.0, A2 = 200000.0, E2 = 120000.0, A3 = 300000.0, E3 = 100000.0\n",
      "Gas constant: R = 8.314\n",
      "\n",
      "Domain bounds:\n",
      "x_min = 0.0\n",
      "x_max = 0.1\n",
      "y_min = 0.0\n",
      "y_max = 0.05\n",
      "t_min = 0.0\n",
      "t_max = 10.0\n",
      "\n",
      "Test input shape: (5, 3)\n",
      "Test output shape: (5, 5)\n",
      "\n",
      "Computed gradients:\n",
      "dy_dx shape: (5, 5, 3)\n",
      "y_x shape: (5, 5)\n",
      "y_y shape: (5, 5)\n",
      "y_t shape: (5, 5)\n",
      "y_xx shape: (5, 5)\n",
      "y_yy shape: (5, 5)\n",
      "\n",
      "Computed residuals:\n",
      "Residual 1 shape: (5, 1)\n",
      "Residual 2 shape: (5, 1)\n",
      "Residual 3 shape: (5, 1)\n",
      "Residual 4 shape: (5, 1)\n",
      "Residual 5 shape: (5, 1)\n",
      "\n",
      "Generated collocation points shape: (10, 3)\n",
      "Generated boundary points:\n",
      "inlet shape: (5, 3)\n",
      "substrate shape: (5, 3)\n",
      "left_wall shape: (5, 3)\n",
      "right_wall shape: (5, 3)\n",
      "Generated initial points shape: (10, 3)\n",
      "\n",
      "Entropy regularization test:\n",
      "Original loss: 1.100000023841858\n",
      "Modified loss: 1.1995666027069092\n",
      "Original gradient: 2.0\n",
      "Modified gradient: 1.040000081062317\n",
      "Updated alpha: 0.10000000149011612\n",
      "Updated beta: 10.0\n",
      "Updated alpha at halfway: 0.055000003427267075\n",
      "Updated beta at halfway: 55.0\n",
      "Updated alpha at end: 0.010000002570450306\n",
      "Updated beta at end: 100.0\n",
      "\n",
      "Notebook 1 completed successfully!\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------------------------\n",
    "# Section 6: Testing Framework and Visualization\n",
    "#---------------------------------------------------------------------------\n",
    "\n",
    "# Initialize physical parameters\n",
    "cvd_params = CVDPhysicalParams()\n",
    "print(\"\\nPhysical parameters initialized:\")\n",
    "print(f\"Diffusion coefficients: D_SiH4 = {cvd_params.D_SiH4}, D_Si = {cvd_params.D_Si}, D_H2 = {cvd_params.D_H2}, D_SiH2 = {cvd_params.D_SiH2}\")\n",
    "print(f\"Thermal parameters: k = {cvd_params.thermal_conductivity}, Cp = {cvd_params.specific_heat}, ρ = {cvd_params.density}\")\n",
    "print(f\"Reaction parameters: A1 = {cvd_params.A1}, E1 = {cvd_params.E1}, A2 = {cvd_params.A2}, E2 = {cvd_params.E2}, A3 = {cvd_params.A3}, E3 = {cvd_params.E3}\")\n",
    "print(f\"Gas constant: R = {cvd_params.R}\")\n",
    "\n",
    "# Define domain bounds\n",
    "domain_bounds = {\n",
    "    'x_min': 0.0,\n",
    "    'x_max': 0.1,\n",
    "    'y_min': 0.0,\n",
    "    'y_max': 0.05,\n",
    "    't_min': 0.0,\n",
    "    't_max': 10.0\n",
    "}\n",
    "\n",
    "print(\"\\nDomain bounds:\")\n",
    "for key, value in domain_bounds.items():\n",
    "    print(f\"{key} = {value}\")\n",
    "\n",
    "# Create a simple PINN model to test\n",
    "test_model = PINN([20, 20, 20], activation='tanh', name=\"test_model\")\n",
    "\n",
    "# Create a test input\n",
    "test_input = tf.random.uniform((5, 3))\n",
    "print(\"\\nTest input shape:\", test_input.shape)\n",
    "\n",
    "# Get test output\n",
    "test_output = test_model(test_input)\n",
    "print(\"Test output shape:\", test_output.shape)\n",
    "\n",
    "# Compute test gradients\n",
    "test_grads = test_model.get_gradients(test_input, test_output)\n",
    "print(\"\\nComputed gradients:\")\n",
    "for key, value in test_grads.items():\n",
    "    print(f\"{key} shape: {value.shape}\")\n",
    "\n",
    "# Create PDE residual calculator\n",
    "cvd_pde = CVDPDE(cvd_params)\n",
    "\n",
    "# Compute test residuals\n",
    "test_residuals = cvd_pde.compute_residuals(test_input, test_output, test_grads)\n",
    "print(\"\\nComputed residuals:\")\n",
    "for i, res in enumerate(test_residuals):\n",
    "    print(f\"Residual {i+1} shape: {res.shape}\")\n",
    "\n",
    "# Create data generator and generate sample data\n",
    "data_gen = CVDDataGenerator(domain_bounds)\n",
    "\n",
    "# Test data generation\n",
    "test_collocation = data_gen.generate_collocation_points(10)\n",
    "print(\"\\nGenerated collocation points shape:\", test_collocation.shape)\n",
    "\n",
    "test_boundary = data_gen.generate_boundary_points(5)\n",
    "print(\"Generated boundary points:\")\n",
    "for key, value in test_boundary.items():\n",
    "    print(f\"{key} shape: {value.shape}\")\n",
    "\n",
    "test_initial = data_gen.generate_initial_points(10)\n",
    "print(\"Generated initial points shape:\", test_initial.shape)\n",
    "\n",
    "# Test entropy-regularized loss\n",
    "entropy_loss = EntropyRegularizedLoss(alpha=0.1, beta=10.0)\n",
    "test_losses = [1.0, 1.2, 0.9, 1.1, 1.0]\n",
    "test_current_loss = tf.constant(1.1, dtype=tf.float32)\n",
    "test_current_gradient = tf.constant(2.0, dtype=tf.float32)\n",
    "\n",
    "modified_loss, modified_gradient = entropy_loss.compute_loss(\n",
    "    test_losses, test_current_loss, test_current_gradient\n",
    ")\n",
    "\n",
    "print(\"\\nEntropy regularization test:\")\n",
    "print(f\"Original loss: {test_current_loss.numpy()}\")\n",
    "print(f\"Modified loss: {modified_loss.numpy()}\")\n",
    "print(f\"Original gradient: {test_current_gradient.numpy()}\")\n",
    "print(f\"Modified gradient: {modified_gradient.numpy()}\")\n",
    "\n",
    "# Test parameter scheduling\n",
    "entropy_loss.update_parameters(0, 1000)\n",
    "print(f\"Updated alpha: {entropy_loss.alpha.numpy()}\")\n",
    "print(f\"Updated beta: {entropy_loss.beta.numpy()}\")\n",
    "\n",
    "entropy_loss.update_parameters(500, 1000)\n",
    "print(f\"Updated alpha at halfway: {entropy_loss.alpha.numpy()}\")\n",
    "print(f\"Updated beta at halfway: {entropy_loss.beta.numpy()}\")\n",
    "\n",
    "entropy_loss.update_parameters(1000, 1000)\n",
    "print(f\"Updated alpha at end: {entropy_loss.alpha.numpy()}\")\n",
    "print(f\"Updated beta at end: {entropy_loss.beta.numpy()}\")\n",
    "\n",
    "print(\"\\nNotebook 1 completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628b7b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvdenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
